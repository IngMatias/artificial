{% extends 'base_entry.html' %}
{% load static %}

{% block header %}
  <img class="icon" src="{% static 'icons/venn.png' %}"/>
  <div class="meta-div">
    <h1 class="title">About the Datasets</h1>
    <span class="meta">{{ last_modified }}</span>
  </div>
{% endblock %}

{% block entry %}
<h2 class="table-content-item">
  Definition
</h2>
<p>
  A dataset is a structured collection of information that serves as a fundamental building block for the development and refinement of data-driven models and analytical solutions.
</p>
<h2 class="table-content-item">
  Unstructured Data
</h2>
<p>
  These datasets come in various forms and types, and within the realm of unstructured data, we find several important categories:
</p>
<p>
  <span class="table-content-item">File</span>: When we refer to 'File,' we are talking about individual data files that contain information. These files can be saved in diverse formats, with .csv (Comma-Separated Values) being a common example. These files often store tabular data, but they can encompass a wide range of data types, from text to multimedia. Analyzing data from files is a foundational step in data science and machine learning projects.
</p>
<p>
  <span class="table-content-item">Folder</span>: A 'Folder' denotes an organized collection of files, providing a structured means of storing and distributing information. This organization is essential when dealing with extensive data sources. Folders help maintain data integrity and facilitate data retrieval and management, particularly in larger-scale projects.
</p>
<p>
  <span class="table-content-item">Web</span>: The 'Web' represents a vast and ever-expanding resource for data. Many organizations and researchers tap into the internet to gather valuable information. This includes data extracted from websites, such as Wikipedia, and social media platforms like Facebook and Twitter. Web data can offer unparalleled insights into various facets of human activity, making it a valuable source for data analysis and modeling. However, web data often arrives in unstructured or semi-structured formats, requiring specialized techniques for data extraction and transformation.
</p>
<h2 class="table-content-item">
  Structured Data
</h2>
<p>
  <span class="table-content-item">Databases</span>: Within the category of structured data types, databases represent one of the most professional and organized ways of storing data. Databases are used in a wide range of applications and industries to manage, store, and retrieve information efficiently.
</p>
<h2 class="table-content-item">
  Access methods
</h2>
<p>
  In the realm of data analysis, every dataset type is accompanied by various methods of access, each of which demands careful consideration. Access methods play a crucial role in the effective utilization of data. Some of the common methods of accessing datasets include:
</p>
<p>
  <span class="table-content-item">APIs</span> (Application Programming Interfaces): APIs provide a structured way to interact with datasets, often over the internet. When working with APIs, it's important to be mindful of elements like 'rate limits.' These limits specify the maximum number of requests that can be made within a given time frame. Adhering to rate limits is critical to maintaining good standing with the data provider and ensuring the reliability of data access. Familiarity with API authentication and usage guidelines is essential for successful data retrieval and integration.
</p>
<p>
  <span class="table-content-item">Database Queries</span>: Accessing data stored in databases often involves using query languages like SQL (Structured Query Language). SQL is a standard language for managing and querying relational databases. Proficiency in SQL is a valuable skill for extracting, filtering, and manipulating data stored in databases. Understanding the database schema and the structure of tables is crucial for formulating effective queries.
</p>
<p>
  <span class="table-content-item">Scraping</span>: Scraping is a versatile method by which one program extracts data generated by another program. A common use case is web scraping, where data is collected from websites. When scraping web data, developers need to be aware of ethical and legal considerations, such as website terms of use and copyright restrictions. Additionally, web scraping may require knowledge of HTML and CSS to locate and extract specific elements from web pages.
</p>
<h2 class="table-content-item">
  Dataset Sources
</h2>
<p>
  The data fed into our models has a profound impact on the resulting predictions. Low-quality data can lead to poorly trained models, ultimately resulting in flawed decisions. While this might be acceptable for small-scale academic models, it is wholly unacceptable for models that can lead to financial losses or, even more critically, the loss of human lives due to an incorrectly chosen course of action.
</p>
<p>
  Hence, the pressing need for trusted entities that can ensure data's confidentiality, integrity, and availability.
</p>
<ul>
  <li>
    <a href="https://www.google.com/publicdata/directory">Google Public Data</a> 
  </li>
  <li>
    <a href="https://data.worldbank.org/">Worldbank</a>
  </li>
  <li>
    <a href="https://www.who.int/data/gho">OMS: World Health Organization</a>
  </li>
  <li>
    <a href="http://opendata.cern.ch/">CERN: European Organization for Nuclear Research</a>
  </li>
  <li>
    <a href="https://archive.ics.uci.edu/datasets">UCI</a>
  </li>
</ul>
<p>
  Adhering to usage <span>licenses</span>, ensuring data is <span>up-to-date</span>, and maintaining <span>data quality</span>are prerequisites for responsible and effective data-driven decision-making.
</p>

{% endblock %}